#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FastAPI ç›´æ¥å¼‚æ­¥å‡½æ•°æµ‹è¯•è„šæœ¬
ç›´æ¥æµ‹è¯•å¼‚æ­¥ write_log å‡½æ•°ï¼Œä¸ä¾èµ– HTTP æœåŠ¡å™¨
åŒ…å«å¼‚æ­¥æ‰§è¡ŒéªŒè¯å’Œçº¿ç¨‹éé˜»å¡æµ‹è¯•
"""

import sys
import os
import asyncio
import time
import random
import threading
import concurrent.futures
from datetime import datetime, timezone
from typing import List, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.log_client import write_log, batch_write_logs, get_log_client


# å…¨å±€å˜é‡ç”¨äºç›‘æ§å¼‚æ­¥æ‰§è¡Œ
execution_log = []
thread_usage = {}


def log_execution(event_type: str, thread_id: int, timestamp: float, details: str = ""):
    """è®°å½•æ‰§è¡Œäº‹ä»¶ï¼Œç”¨äºåˆ†æå¼‚æ­¥è¡Œä¸º"""
    execution_log.append({
        'event_type': event_type,
        'thread_id': thread_id,
        'timestamp': timestamp,
        'details': details,
        'readable_time': datetime.fromtimestamp(timestamp).strftime('%H:%M:%S.%f')[:-3]
    })
    
    if thread_id not in thread_usage:
        thread_usage[thread_id] = 0
    thread_usage[thread_id] += 1


async def test_async_execution_verification():
    """éªŒè¯å¼‚æ­¥æ‰§è¡Œçš„éé˜»å¡ç‰¹æ€§"""
    print("=== ğŸ” å¼‚æ­¥æ‰§è¡ŒéªŒè¯æµ‹è¯• ===")
    print("æ­¤æµ‹è¯•éªŒè¯å¼‚æ­¥è°ƒç”¨æ˜¯å¦çœŸæ­£éé˜»å¡ï¼Œæ˜¯å¦åœ¨ä¸åŒçº¿ç¨‹ä¸­æ‰§è¡Œ\n")
    
    main_thread_id = threading.get_ident()
    log_execution("test_start", main_thread_id, time.time(), "ä¸»æµ‹è¯•çº¿ç¨‹")
    
    # åˆ›å»ºå¤šä¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œè®°å½•å®ƒä»¬çš„æ‰§è¡Œæƒ…å†µ
    async def traced_write_log(index: int, delay: float = 0):
        """å¸¦è¿½è¸ªçš„å¼‚æ­¥æ—¥å¿—å†™å…¥"""
        current_thread = threading.get_ident()
        start_time = time.time()
        
        log_execution("task_start", current_thread, start_time, f"ä»»åŠ¡{index}å¼€å§‹")
        
        # å¯é€‰çš„å»¶è¿Ÿæ¥è§‚å¯Ÿå¹¶å‘
        if delay > 0:
            await asyncio.sleep(delay)
        
        try:
            result = await write_log(
                f"å¼‚æ­¥éªŒè¯æµ‹è¯•æ¶ˆæ¯ {index}",
                service_name="async-verification-test",
                task_id=index,
                thread_id=current_thread,
                start_timestamp=start_time
            )
            
            end_time = time.time()
            log_execution("task_complete", current_thread, end_time, 
                         f"ä»»åŠ¡{index}å®Œæˆï¼Œè€—æ—¶{end_time-start_time:.3f}s")
            
            return result
            
        except Exception as e:
            end_time = time.time()
            log_execution("task_error", current_thread, end_time, 
                         f"ä»»åŠ¡{index}å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}
    
    # 1. æµ‹è¯•ç®€å•çš„éé˜»å¡å¼‚æ­¥è°ƒç”¨
    print("ğŸ“ æµ‹è¯•1: ç®€å•å¼‚æ­¥è°ƒç”¨éªŒè¯")
    task1 = traced_write_log(1)
    task2 = traced_write_log(2)
    task3 = traced_write_log(3)
    
    start_concurrent = time.time()
    results = await asyncio.gather(task1, task2, task3)
    end_concurrent = time.time()
    
    print(f"âœ… 3ä¸ªä»»åŠ¡å¹¶å‘æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {end_concurrent - start_concurrent:.3f}ç§’")
    
    # 2. æµ‹è¯•å¸¦å»¶è¿Ÿçš„å¼‚æ­¥è°ƒç”¨ï¼ˆæ›´æ˜æ˜¾çš„å¹¶å‘æ•ˆæœï¼‰
    print("\nğŸ“ æµ‹è¯•2: å¸¦å»¶è¿Ÿçš„å¹¶å‘å¼‚æ­¥è°ƒç”¨")
    delayed_tasks = [
        traced_write_log(f"delayed-{i}", delay=0.1) 
        for i in range(5)
    ]
    
    start_delayed = time.time()
    delayed_results = await asyncio.gather(*delayed_tasks)
    end_delayed = time.time()
    
    print(f"âœ… 5ä¸ªå¸¦å»¶è¿Ÿä»»åŠ¡å¹¶å‘æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {end_delayed - start_delayed:.3f}ç§’")
    print(f"   å¦‚æœæ˜¯ä¸²è¡Œæ‰§è¡Œï¼Œé¢„æœŸè€—æ—¶åº”è¯¥ > 0.5ç§’")
    print(f"   å®é™…å¹¶å‘æ‰§è¡Œè€—æ—¶: {end_delayed - start_delayed:.3f}ç§’")
    
    # 3. åˆ†ææ‰§è¡Œçº¿ç¨‹ä½¿ç”¨æƒ…å†µ
    print(f"\nğŸ“Š çº¿ç¨‹ä½¿ç”¨åˆ†æ:")
    print(f"ä¸»çº¿ç¨‹ID: {main_thread_id}")
    print(f"ä½¿ç”¨çš„çº¿ç¨‹æ•°é‡: {len(thread_usage)}")
    for thread_id, count in thread_usage.items():
        thread_type = "ä¸»çº¿ç¨‹" if thread_id == main_thread_id else "å·¥ä½œçº¿ç¨‹"
        print(f"  çº¿ç¨‹{thread_id} ({thread_type}): æ‰§è¡Œäº† {count} ä¸ªäº‹ä»¶")
    
    # 4. æ—¶é—´è½´åˆ†æ
    print(f"\nğŸ“… æ‰§è¡Œæ—¶é—´è½´åˆ†æ:")
    execution_log.sort(key=lambda x: x['timestamp'])
    
    start_time = execution_log[0]['timestamp'] if execution_log else time.time()
    overlapping_tasks = 0
    
    for i, event in enumerate(execution_log[-10:]):  # æ˜¾ç¤ºæœ€å10ä¸ªäº‹ä»¶
        relative_time = (event['timestamp'] - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        print(f"  {relative_time:6.1f}ms [{event['thread_id']}] {event['event_type']}: {event['details']}")
    
    # 5. æ£€æŸ¥çœŸæ­£çš„å¹¶å‘æ€§
    task_starts = [e for e in execution_log if e['event_type'] == 'task_start']
    if len(task_starts) >= 2:
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å‡ ä¹åŒæ—¶å¼€å§‹ï¼ˆè¯æ˜éé˜»å¡ï¼‰
        time_diffs = []
        for i in range(1, len(task_starts)):
            diff = (task_starts[i]['timestamp'] - task_starts[i-1]['timestamp']) * 1000
            time_diffs.append(diff)
        
        avg_start_diff = sum(time_diffs) / len(time_diffs)
        print(f"\nâš¡ å¹¶å‘æ€§åˆ†æ:")
        print(f"  ä»»åŠ¡å¯åŠ¨å¹³å‡é—´éš”: {avg_start_diff:.2f}æ¯«ç§’")
        if avg_start_diff < 10:  # å°äº10æ¯«ç§’è®¤ä¸ºæ˜¯çœŸæ­£å¹¶å‘
            print(f"  âœ… ç¡®è®¤ä¸ºçœŸæ­£çš„å¼‚æ­¥å¹¶å‘æ‰§è¡Œ (é—´éš” < 10ms)")
        else:
            print(f"  âš ï¸  å¯èƒ½å­˜åœ¨é˜»å¡ï¼Œä»»åŠ¡å¯åŠ¨é—´éš”è¾ƒå¤§")
    
    return len([r for r in results + delayed_results if r.get('success', False)])


async def test_write_log_function():
    """æµ‹è¯•å¼‚æ­¥ write_log å‡½æ•°"""
    print("\n=== æµ‹è¯•å¼‚æ­¥ write_log å‡½æ•° ===")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    result = await write_log(
        "æµ‹è¯•æ¶ˆæ¯ï¼šFastAPIå¼‚æ­¥åŸºæœ¬åŠŸèƒ½æµ‹è¯•",
        service_name="fastapi-direct-test",
        level="INFO",
        trace_id="direct-trace-001",
        span_id="direct-span-001",
        adv_id=1234567,
        aweme_id=987654321,
        plan_id=12345,
        monitor_type="impression",
        co_id=5678,
        test_type="direct_async_function_call",
        client_type="fastapi_async"
    )
    
    print(f"æµ‹è¯•ç»“æœ: {result}")
    return result.get('success', False)


async def test_concurrent_write_log(count: int = 1000):
    """æµ‹è¯•å¹¶å‘å¼‚æ­¥è°ƒç”¨ write_log å‡½æ•°"""
    print(f"\n=== å¹¶å‘æµ‹è¯•å¼‚æ­¥ write_log å‡½æ•° ({count} æ¬¡è°ƒç”¨) ===")
    
    async def write_single_log(index: int):
        """å†™å…¥å•æ¡å¼‚æ­¥æ—¥å¿—"""
        try:
            return await write_log(
                f"FastAPIå¼‚æ­¥å¹¶å‘æµ‹è¯•æ¶ˆæ¯ {index}",
                service_name="fastapi-concurrent-direct",
                level=random.choice(["DEBUG", "INFO", "WARN", "ERROR"]),
                trace_id=f"concurrent-direct-{index:06d}",
                span_id=f"span-{index:06d}",
                adv_id=random.randint(1000000, 9999999),
                aweme_id=random.randint(100000000, 999999999),
                plan_id=random.randint(10000, 99999),
                monitor_type=random.choice(["impression", "click", "conversion", "view"]),
                co_id=random.randint(1000, 9999),
                index=index,
                timestamp=datetime.now().isoformat(),
                client_type="fastapi_async_direct"
            )
        except Exception as e:
            return {
                'success': False,
                'log_id': '',
                'error_message': str(e)
            }
    
    start_time = time.time()
    
    # åˆ›å»ºå¹¶å‘ä»»åŠ¡
    tasks = [write_single_log(i) for i in range(1, count + 1)]
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    end_time = time.time()
    duration = end_time - start_time
    
    # ç»Ÿè®¡ç»“æœ
    success_count = 0
    failed_count = 0
    errors = []
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            failed_count += 1
            errors.append(f"Task {i+1}: {str(result)}")
        elif isinstance(result, dict):
            if result.get('success'):
                success_count += 1
            else:
                failed_count += 1
                errors.append(f"Task {i+1}: {result.get('error_message', 'Unknown error')}")
        else:
            failed_count += 1
            errors.append(f"Task {i+1}: Unexpected result type")
    
    print(f"\nå¼‚æ­¥å¹¶å‘æµ‹è¯•ç»“æœ:")
    print(f"æ€»è€—æ—¶: {duration:.3f} ç§’")
    print(f"æˆåŠŸå†™å…¥: {success_count}/{count}")
    print(f"å¤±è´¥å†™å…¥: {failed_count}")
    print(f"å†™å…¥é€Ÿåº¦: {success_count / duration:.2f} logs/second")
    
    # æ˜¾ç¤ºå¤±è´¥ç¤ºä¾‹
    if errors:
        print("\nå¤±è´¥ç¤ºä¾‹:")
        for i, error in enumerate(errors[:5], 1):
            print(f"  {i}. {error}")
    
    return success_count > count * 0.9  # æˆåŠŸç‡è¶…è¿‡90%è®¤ä¸ºæµ‹è¯•é€šè¿‡


async def test_batch_write_logs(count: int = 500):
    """æµ‹è¯•å¼‚æ­¥æ‰¹é‡å†™å…¥å‡½æ•°"""
    print(f"\n=== æµ‹è¯•å¼‚æ­¥æ‰¹é‡å†™å…¥å‡½æ•° ({count} æ¡æ—¥å¿—) ===")
    
    # ç”Ÿæˆæµ‹è¯•æ—¥å¿—æ¡ç›®
    log_entries = []
    for i in range(count):
        entry = {
            "message": f"FastAPIå¼‚æ­¥æ‰¹é‡æµ‹è¯•æ—¥å¿— {i+1}/{count}",
            "service_name": "fastapi-batch-direct",
            "level": random.choice(["DEBUG", "INFO", "WARN", "ERROR"]),
            "trace_id": f"batch-direct-{i+1:06d}",
            "span_id": f"span-{i+1:06d}",
            "adv_id": random.randint(1000000, 9999999),
            "aweme_id": random.randint(100000000, 999999999),
            "plan_id": random.randint(10000, 99999),
            "monitor_type": random.choice(["impression", "click", "conversion", "view"]),
            "co_id": random.randint(1000, 9999),
            "batch_index": i + 1,
            "timestamp": datetime.now().isoformat(),
            "client_type": "fastapi_async_batch"
        }
        log_entries.append(entry)
    
    start_time = time.time()
    
    # å¼‚æ­¥æ‰¹é‡å†™å…¥
    result = await batch_write_logs(log_entries)
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nå¼‚æ­¥æ‰¹é‡å†™å…¥ç»“æœ:")
    print(f"æ€»è€—æ—¶: {duration:.3f} ç§’")
    print(f"æ€»æ•°é‡: {result.get('total_count', 0)}")
    print(f"æˆåŠŸå†™å…¥: {result.get('success_count', 0)}")
    print(f"å¤±è´¥å†™å…¥: {result.get('error_count', 0)}")
    print(f"å†™å…¥é€Ÿåº¦: {result.get('success_count', 0) / duration:.2f} logs/second")
    
    # æ˜¾ç¤ºé”™è¯¯ç¤ºä¾‹
    errors = result.get('errors', [])
    if errors:
        print("é”™è¯¯ç¤ºä¾‹:")
        for i, error in enumerate(errors[:3], 1):
            print(f"  {i}. {error}")
    
    return result.get('success_count', 0) > count * 0.9


async def test_large_scale_concurrent(count: int = 5000):
    """å¤§è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯•"""
    print(f"\n=== å¤§è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯• ({count} æ¬¡è°ƒç”¨) ===")
    
    # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…åˆ›å»ºè¿‡å¤šåç¨‹
    batch_size = 100
    batches = [list(range(i, min(i + batch_size, count))) for i in range(0, count, batch_size)]
    
    print(f"åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} ä¸ªåç¨‹")
    
    async def process_batch(batch_indices):
        """å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ—¥å¿—å†™å…¥"""
        tasks = []
        for i in batch_indices:
            task = write_log(
                f"FastAPIå¤§è§„æ¨¡å¼‚æ­¥æµ‹è¯•æ¶ˆæ¯ {i+1}",
                service_name="fastapi-large-scale",
                level=random.choice(["DEBUG", "INFO", "WARN", "ERROR"]),
                trace_id=f"large-scale-{i+1:06d}",
                span_id=f"span-{i+1:06d}",
                adv_id=random.randint(1000000, 9999999),
                aweme_id=random.randint(100000000, 999999999),
                plan_id=random.randint(10000, 99999),
                monitor_type=random.choice(["impression", "click", "conversion", "view"]),
                co_id=random.randint(1000, 9999),
                batch_id=len(batch_indices),
                item_index=i + 1,
                timestamp=datetime.now().isoformat(),
                client_type="fastapi_async_large_scale"
            )
            tasks.append(task)
        
        return await asyncio.gather(*tasks, return_exceptions=True)
    
    start_time = time.time()
    
    # å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¹æ¬¡
    batch_tasks = [process_batch(batch) for batch in batches]
    batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
    
    end_time = time.time()
    duration = end_time - start_time
    
    # æ±‡æ€»ç»“æœ
    all_results = []
    for batch_result in batch_results:
        if isinstance(batch_result, Exception):
            print(f"æ‰¹æ¬¡å¤„ç†å¼‚å¸¸: {batch_result}")
            continue
        all_results.extend(batch_result)
    
    success_count = 0
    failed_count = 0
    errors = []
    
    for i, result in enumerate(all_results):
        if isinstance(result, Exception):
            failed_count += 1
            errors.append(f"Item {i+1}: {str(result)}")
        elif isinstance(result, dict):
            if result.get('success'):
                success_count += 1
            else:
                failed_count += 1
                errors.append(f"Item {i+1}: {result.get('error_message', 'Unknown error')}")
    
    print(f"\nå¤§è§„æ¨¡å¼‚æ­¥æµ‹è¯•ç»“æœ:")
    print(f"æ€»è€—æ—¶: {duration:.3f} ç§’")
    print(f"å®é™…å¤„ç†: {len(all_results)} æ¡")
    print(f"æˆåŠŸå†™å…¥: {success_count}")
    print(f"å¤±è´¥å†™å…¥: {failed_count}")
    print(f"æˆåŠŸç‡: {success_count / len(all_results) * 100:.2f}%")
    print(f"å†™å…¥é€Ÿåº¦: {success_count / duration:.2f} logs/second")
    
    return success_count > len(all_results) * 0.95  # æˆåŠŸç‡è¶…è¿‡95%


async def main():
    """ä¸»å‡½æ•°"""
    print("=== FastAPI Log Service ç›´æ¥å¼‚æ­¥å‡½æ•°æµ‹è¯• ===")
    print("æ³¨æ„ï¼šæ­¤æµ‹è¯•ç›´æ¥è°ƒç”¨å¼‚æ­¥ write_log å‡½æ•°ï¼Œéœ€è¦ gRPC æœåŠ¡å™¨è¿è¡Œ")
    print()
    
    try:
        # ğŸ” æµ‹è¯•0: å¼‚æ­¥æ‰§è¡ŒéªŒè¯ (æ–°å¢)
        successful_verifications = await test_async_execution_verification()
        print(f"âœ… å¼‚æ­¥æ‰§è¡ŒéªŒè¯å®Œæˆï¼ŒæˆåŠŸéªŒè¯ {successful_verifications} ä¸ªä»»åŠ¡")
        
        # æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½
        if await test_write_log_function():
            print("âœ… å¼‚æ­¥åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ å¼‚æ­¥åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return
        
        # æµ‹è¯•2: ä¸­ç­‰è§„æ¨¡å¹¶å‘
        if await test_concurrent_write_log(1000):
            print("âœ… ä¸­ç­‰è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ ä¸­ç­‰è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯•å¤±è´¥")
        
        # æµ‹è¯•3: æ‰¹é‡å†™å…¥
        if await test_batch_write_logs(500):
            print("âœ… å¼‚æ­¥æ‰¹é‡å†™å…¥æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ å¼‚æ­¥æ‰¹é‡å†™å…¥æµ‹è¯•å¤±è´¥")
        
        # è¯¢é—®æ˜¯å¦è¿›è¡Œå¤§è§„æ¨¡æµ‹è¯•
        choice = input("\næ˜¯å¦è¿›è¡Œå¤§è§„æ¨¡å¼‚æ­¥æµ‹è¯• (5000æ¬¡å¹¶å‘)? [y/N]: ").lower()
        if choice == 'y':
            if await test_large_scale_concurrent(5000):
                print("âœ… å¤§è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ å¤§è§„æ¨¡å¼‚æ­¥å¹¶å‘æµ‹è¯•å¤±è´¥")
        
        print("\nğŸ‰ å¼‚æ­¥æµ‹è¯•å®Œæˆ!")
        
        # æ¸…ç†è¿æ¥
        client = get_log_client()
        await client.disconnect()
    
    except Exception as e:
        print(f"âŒ å¼‚æ­¥æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"å¼‚æ­¥æµ‹è¯•å¤±è´¥: {e}")
