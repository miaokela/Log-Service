#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç®€å•æµ‹è¯•è„šæœ¬ - ç›´æ¥æµ‹è¯• write_log å‡½æ•°
ä¸ä¾èµ– Django æœåŠ¡å™¨ï¼Œç›´æ¥è¿æ¥ gRPC æœåŠ¡
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½® Django ç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'log_service_django.settings')

import django
django.setup()

from log_client.client import write_log
import log_service_pb2
import time
import random
import concurrent.futures
from datetime import datetime


def test_write_log_function():
    """æµ‹è¯• write_log å‡½æ•°"""
    print("=== æµ‹è¯• write_log å‡½æ•° ===")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    result = write_log(
        "æµ‹è¯•æ¶ˆæ¯ï¼šåŸºæœ¬åŠŸèƒ½æµ‹è¯•",
        service_name="django-direct-test",
        level="INFO",
        trace_id="direct-trace-001",
        span_id="direct-span-001",
        adv_id=1234567,
        aweme_id=987654321,
        plan_id=12345,
        monitor_type="impression",
        co_id=5678,
        test_type="direct_function_call"
    )
    
    print(f"æµ‹è¯•ç»“æœ: {result}")
    return result.get('success', False)


def test_concurrent_write_log(count: int = 1000):
    """æµ‹è¯•å¹¶å‘è°ƒç”¨ write_log å‡½æ•°"""
    print(f"\n=== å¹¶å‘æµ‹è¯• write_log å‡½æ•° ({count} æ¬¡è°ƒç”¨) ===")
    
    def write_single_log(index):
        """å†™å…¥å•æ¡æ—¥å¿—"""
        try:
            return write_log(
                f"å¹¶å‘æµ‹è¯•æ¶ˆæ¯ {index}",
                service_name="django-concurrent-direct",
                level=random.choice(["DEBUG", "INFO", "WARN", "ERROR"]),
                trace_id=f"concurrent-direct-{index:06d}",
                span_id=f"span-{index:06d}",
                adv_id=random.randint(1000000, 9999999),
                aweme_id=random.randint(100000000, 999999999),
                plan_id=random.randint(10000, 99999),
                monitor_type=random.choice(["impression", "click", "conversion", "view"]),
                co_id=random.randint(1000, 9999),
                index=index,
                timestamp=datetime.now().isoformat()
            )
        except Exception as e:
            return {
                'success': False,
                'log_id': '',
                'error_message': str(e)
            }
    
    start_time = time.time()
    results = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘æµ‹è¯•
    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
        future_to_index = {
            executor.submit(write_single_log, i): i 
            for i in range(1, count + 1)
        }
        
        for future in concurrent.futures.as_completed(future_to_index):
            try:
                result = future.result()
                results.append(result)
                
                if len(results) % 100 == 0:
                    print(f"å·²å®Œæˆ: {len(results)}/{count}")
            
            except Exception as e:
                results.append({
                    'success': False,
                    'log_id': '',
                    'error_message': str(e)
                })
    
    end_time = time.time()
    duration = end_time - start_time
    
    success_count = sum(1 for r in results if r.get('success'))
    failed_count = count - success_count
    
    print(f"\nå¹¶å‘æµ‹è¯•ç»“æœ:")
    print(f"æ€»è€—æ—¶: {duration:.3f} ç§’")
    print(f"æˆåŠŸå†™å…¥: {success_count}/{count}")
    print(f"å¤±è´¥å†™å…¥: {failed_count}")
    print(f"å†™å…¥é€Ÿåº¦: {success_count / duration:.2f} logs/second")
    
    # æ˜¾ç¤ºå¤±è´¥ç¤ºä¾‹
    failed_results = [r for r in results if not r.get('success')]
    if failed_results:
        print("\nå¤±è´¥ç¤ºä¾‹:")
        for i, result in enumerate(failed_results[:5], 1):
            print(f"  {i}. {result.get('error_message', 'Unknown error')}")
    
    return success_count > count * 0.9  # æˆåŠŸç‡è¶…è¿‡90%è®¤ä¸ºæµ‹è¯•é€šè¿‡


def test_large_scale_concurrent(count: int = 10000):
    """å¤§è§„æ¨¡å¹¶å‘æµ‹è¯•"""
    print(f"\n=== å¤§è§„æ¨¡å¹¶å‘æµ‹è¯• ({count} æ¬¡è°ƒç”¨) ===")
    
    def write_batch_logs(start_index, batch_size):
        """æ‰¹é‡å†™å…¥æ—¥å¿—"""
        results = []
        for i in range(start_index, start_index + batch_size):
            try:
                result = write_log(
                    f"å¤§è§„æ¨¡æµ‹è¯•æ¶ˆæ¯ {i}",
                    service_name="django-large-scale",
                    level=random.choice(["DEBUG", "INFO", "WARN", "ERROR"]),
                    trace_id=f"large-scale-{i:06d}",
                    span_id=f"span-{i:06d}",
                    adv_id=random.randint(1000000, 9999999),
                    aweme_id=random.randint(100000000, 999999999),
                    plan_id=random.randint(10000, 99999),
                    monitor_type=random.choice(["impression", "click", "conversion", "view"]),
                    co_id=random.randint(1000, 9999),
                    batch_index=start_index // 100,
                    item_index=i,
                    timestamp=datetime.now().isoformat()
                )
                results.append(result)
            except Exception as e:
                results.append({
                    'success': False,
                    'log_id': '',
                    'error_message': str(e)
                })
        return results
    
    start_time = time.time()
    all_results = []
    
    # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹100æ¡
    batch_size = 100
    max_workers = 50
    
    batches = [(i, min(batch_size, count - i)) for i in range(0, count, batch_size)]
    
    print(f"åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} æ¡æ—¥å¿—")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_batch = {
            executor.submit(write_batch_logs, start_idx, size): (start_idx, size)
            for start_idx, size in batches
        }
        
        completed_batches = 0
        for future in concurrent.futures.as_completed(future_to_batch):
            try:
                batch_results = future.result()
                all_results.extend(batch_results)
                
                completed_batches += 1
                if completed_batches % 10 == 0:
                    print(f"å·²å®Œæˆæ‰¹æ¬¡: {completed_batches}/{len(batches)}")
            
            except Exception as e:
                print(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
    
    end_time = time.time()
    duration = end_time - start_time
    
    success_count = sum(1 for r in all_results if r.get('success'))
    failed_count = len(all_results) - success_count
    
    print(f"\nå¤§è§„æ¨¡æµ‹è¯•ç»“æœ:")
    print(f"æ€»è€—æ—¶: {duration:.3f} ç§’")
    print(f"å®é™…å¤„ç†: {len(all_results)} æ¡")
    print(f"æˆåŠŸå†™å…¥: {success_count}")
    print(f"å¤±è´¥å†™å…¥: {failed_count}")
    print(f"æˆåŠŸç‡: {success_count / len(all_results) * 100:.2f}%")
    print(f"å†™å…¥é€Ÿåº¦: {success_count / duration:.2f} logs/second")
    
    return success_count > len(all_results) * 0.95  # æˆåŠŸç‡è¶…è¿‡95%


def main():
    """ä¸»å‡½æ•°"""
    print("=== Django Log Service ç›´æ¥å‡½æ•°æµ‹è¯• ===")
    print("æ³¨æ„ï¼šæ­¤æµ‹è¯•ç›´æ¥è°ƒç”¨ write_log å‡½æ•°ï¼Œéœ€è¦ gRPC æœåŠ¡å™¨è¿è¡Œ")
    print()
    
    try:
        # æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½
        if test_write_log_function():
            print("âœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return
        
        # æµ‹è¯•2: ä¸­ç­‰è§„æ¨¡å¹¶å‘
        if test_concurrent_write_log(1000):
            print("âœ… ä¸­ç­‰è§„æ¨¡å¹¶å‘æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ ä¸­ç­‰è§„æ¨¡å¹¶å‘æµ‹è¯•å¤±è´¥")
        
        # è¯¢é—®æ˜¯å¦è¿›è¡Œå¤§è§„æ¨¡æµ‹è¯•
        choice = input("\næ˜¯å¦è¿›è¡Œå¤§è§„æ¨¡æµ‹è¯• (1ä¸‡æ¬¡å¹¶å‘)? [y/N]: ").lower()
        if choice == 'y':
            if test_large_scale_concurrent(10000):
                print("âœ… å¤§è§„æ¨¡å¹¶å‘æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ å¤§è§„æ¨¡å¹¶å‘æµ‹è¯•å¤±è´¥")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()
